import streamlit as st
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD, NMF
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import plotly.express as px
import plotly.graph_objects as go
from scipy.sparse import csr_matrix
import warnings
warnings.filterwarnings('ignore')

class EnsembleRecommenderSystem:
    def __init__(self):
        self.svd_model = None
        self.nmf_model = None
        self.rf_model = None
        self.item_similarity = None
        self.user_item_matrix = None
        self.scaler = StandardScaler()
        self.le_magazin = LabelEncoder()
        self.le_art = LabelEncoder()
        self.processed_data = None
        self.feature_columns = []
        self.content_features = None
        self.weights = {'svd': 0.4, 'nmf': 0.3, 'similarity': 0.2, 'content': 0.1}
        
    def preprocess_data(self, df):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            df['Datasales'] = pd.to_datetime(df['Datasales'], errors='coerce')
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã: {e}")
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        df = df.dropna(subset=['Magazin', 'Art', 'Price', 'Qty', 'Datasales'])
        
        if len(df) == 0:
            raise ValueError("–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å—Ç—Ä–æ–∫")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df['Month'] = df['Datasales'].dt.month
        df['Quarter'] = df['Datasales'].dt.quarter
        df['Weekday'] = df['Datasales'].dt.dayofweek
        df['DayOfMonth'] = df['Datasales'].dt.day
        
        # –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏
        df['Revenue'] = df['Price'] * df['Qty']
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        try:
            df['PriceCategory'] = pd.cut(df['Price'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])
        except Exception:
            df['PriceCategory'] = 'Medium'  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –≠–Ω–∫–æ–¥–∏–Ω–≥ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        df['magazin_encoded'] = self.le_magazin.fit_transform(df['Magazin'].astype(str))
        df['art_encoded'] = self.le_art.fit_transform(df['Art'].astype(str))
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        categorical_cols = ['Segment', 'Model', 'Describe']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].fillna('Unknown')
            else:
                df[col] = 'Unknown'
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω-—Ç–æ–≤–∞—Ä
        try:
            agg_data = df.groupby(['magazin_encoded', 'art_encoded', 'Magazin', 'Art']).agg({
                'Qty': ['sum', 'mean', 'count'],
                'Revenue': ['sum', 'mean'],
                'Price': ['mean', 'min', 'max'],
                'Month': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],
                'Segment': 'first',
                'Model': 'first',
                'Describe': 'first'
            }).reset_index()
            
            # –£–ø—Ä–æ—â–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
            agg_data.columns = ['magazin_encoded', 'art_encoded', 'Magazin', 'Art', 
                               'qty_sum', 'qty_mean', 'freq', 'revenue_sum', 'revenue_mean',
                               'price_mean', 'price_min', 'price_max', 'peak_month',
                               'Segment', 'Model', 'Describe']
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        agg_data['qty_sum'] = np.maximum(agg_data['qty_sum'], 1e-8)
        agg_data['revenue_sum'] = np.maximum(agg_data['revenue_sum'], 1e-8)
        agg_data['freq'] = np.maximum(agg_data['freq'], 1)
        
        agg_data['rating'] = (
            np.log1p(agg_data['qty_sum']) * 0.4 +
            np.log1p(agg_data['revenue_sum']) * 0.4 +
            np.log1p(agg_data['freq']) * 0.2
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        rating_min = agg_data['rating'].min()
        rating_max = agg_data['rating'].max()
        
        if rating_max - rating_min > 1e-8:
            agg_data['rating'] = (agg_data['rating'] - rating_min) / (rating_max - rating_min) * 4 + 1
        else:
            agg_data['rating'] = 2.5  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –µ—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
        
        self.processed_data = agg_data
        return agg_data
    
    def create_user_item_matrix(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä"""
        n_users = df['magazin_encoded'].nunique()
        n_items = df['art_encoded'].nunique()
        
        if n_users == 0 or n_items == 0:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
        try:
            user_item_matrix = csr_matrix((df['rating'], 
                                         (df['magazin_encoded'], df['art_encoded'])), 
                                        shape=(n_users, n_items))
            
            self.user_item_matrix = user_item_matrix.toarray()
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã: {e}")
        
        return self.user_item_matrix
    
    def prepare_content_features(self, df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
            item_features = df.groupby('art_encoded').agg({
                'price_mean': 'first',
                'Segment': 'first',
                'Model': 'first',
                'qty_mean': 'first',
                'revenue_mean': 'first'
            }).reset_index()
            
            # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            segment_dummies = pd.get_dummies(item_features['Segment'], prefix='segment')
            model_dummies = pd.get_dummies(item_features['Model'], prefix='model')
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = pd.concat([
                item_features[['art_encoded', 'price_mean', 'qty_mean', 'revenue_mean']],
                segment_dummies,
                model_dummies
            ], axis=1)
            
            self.feature_columns = [col for col in features.columns if col != 'art_encoded']
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            numeric_cols = ['price_mean', 'qty_mean', 'revenue_mean']
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            for col in numeric_cols:
                if features[col].std() > 1e-8:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
                    features[[col]] = self.scaler.fit_transform(features[[col]])
                else:
                    features[col] = 0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ –Ω—É–ª—é –µ—Å–ª–∏ –Ω–µ—Ç –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
            
            self.content_features = features
            return features
        
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return pd.DataFrame()
    
    def build_ensemble_model(self, df, test_size=0.2):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            df = self.preprocess_data(df)
            user_item_matrix = self.create_user_item_matrix(df)
            content_features = self.prepare_content_features(df)
            
            if len(df) < 10:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–º–∏–Ω–∏–º—É–º 10 –∑–∞–ø–∏—Å–µ–π)")
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            train_data, test_data = train_test_split(df, test_size=min(test_size, 0.5), random_state=42)
            
            # 1. SVD (Matrix Factorization)
            n_components_svd = min(50, min(user_item_matrix.shape) - 1)
            if n_components_svd > 0:
                self.svd_model = TruncatedSVD(n_components=n_components_svd, random_state=42)
                svd_matrix = self.svd_model.fit_transform(user_item_matrix)
            
            # 2. NMF (Non-negative Matrix Factorization)
            n_components_nmf = min(30, min(user_item_matrix.shape) - 1)
            if n_components_nmf > 0:
                try:
                    self.nmf_model = NMF(n_components=n_components_nmf, random_state=42, max_iter=500)
                    nmf_matrix = self.nmf_model.fit_transform(np.maximum(user_item_matrix, 0))
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ NMF: {e}")
                    self.nmf_model = None
            
            # 3. Item-based Collaborative Filtering
            if user_item_matrix.shape[1] > 1:
                self.item_similarity = cosine_similarity(user_item_matrix.T)
            
            # 4. Content-based Random Forest
            if len(content_features) > 0 and len(self.feature_columns) > 0:
                try:
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RF
                    rf_data = df.merge(content_features, on='art_encoded', how='left')
                    X_rf = rf_data[self.feature_columns].fillna(0)
                    y_rf = rf_data['rating']
                    
                    if len(X_rf) > 5:  # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RF
                        self.rf_model = RandomForestRegressor(
                            n_estimators=min(100, len(X_rf) * 2), 
                            random_state=42, 
                            max_depth=min(10, len(self.feature_columns))
                        )
                        self.rf_model.fit(X_rf, y_rf)
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ Random Forest: {e}")
                    self.rf_model = None
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            try:
                train_predictions = self.predict_ratings_for_evaluation(train_data)
                test_predictions = self.predict_ratings_for_evaluation(test_data)
                
                train_rmse = np.sqrt(np.mean((train_data['rating'] - train_predictions) ** 2))
                test_rmse = np.sqrt(np.mean((test_data['rating'] - test_predictions) ** 2))
            except Exception as e:
                st.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
                train_rmse = test_rmse = 0.0
            
            return {
                'train_rmse': train_rmse,
                'test_rmse': test_rmse,
                'n_users': len(df['magazin_encoded'].unique()),
                'n_items': len(df['art_encoded'].unique()),
                'sparsity': 1 - np.count_nonzero(user_item_matrix) / (user_item_matrix.shape[0] * user_item_matrix.shape[1])
            }
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def predict_ratings_for_evaluation(self, test_data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""
        predictions = []
        
        for _, row in test_data.iterrows():
            user_id = row['magazin_encoded']
            item_id = row['art_encoded']
            
            pred = self.predict_single_rating(user_id, item_id)
            predictions.append(pred)
        
        return np.array(predictions)
    
    def predict_single_rating(self, user_id, item_id):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞"""
        predictions = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü
        if (self.user_item_matrix is None or 
            user_id >= self.user_item_matrix.shape[0] or 
            item_id >= self.user_item_matrix.shape[1]):
            return 2.5
        
        # SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.svd_model is not None:
            try:
                user_factors = self.svd_model.transform(self.user_item_matrix[user_id:user_id+1])
                item_factors = self.svd_model.components_[:, item_id]
                svd_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
                predictions.append(('svd', svd_pred))
            except Exception:
                pass
        
        # NMF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.nmf_model is not None:
            try:
                user_matrix = np.maximum(self.user_item_matrix[user_id:user_id+1], 0)
                user_factors = self.nmf_model.transform(user_matrix)
                item_factors = self.nmf_model.components_[:, item_id]
                nmf_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
                predictions.append(('nmf', nmf_pred))
            except Exception:
                pass
        
        # Item similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.item_similarity is not None:
            try:
                user_ratings = self.user_item_matrix[user_id]
                similar_items = self.item_similarity[item_id]
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–æ—Ö–æ–∂–∏–º —Ç–æ–≤–∞—Ä–∞–º
                numerator = np.sum(similar_items * user_ratings)
                denominator = np.sum(np.abs(similar_items))
                
                if denominator > 1e-8:
                    similarity_pred = numerator / denominator
                    predictions.append(('similarity', similarity_pred))
            except Exception:
                pass
        
        # Content-based –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.rf_model is not None and self.content_features is not None:
            try:
                item_features = self.content_features[
                    self.content_features['art_encoded'] == item_id
                ]
                if len(item_features) > 0:
                    X_content = item_features[self.feature_columns].fillna(0)
                    content_pred = self.rf_model.predict(X_content)[0]
                    predictions.append(('content', content_pred))
            except Exception:
                pass
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if predictions:
            weighted_sum = sum(pred * self.weights.get(method, 0.25) for method, pred in predictions)
            total_weight = sum(self.weights.get(method, 0.25) for method, _ in predictions)
            final_pred = weighted_sum / total_weight if total_weight > 0 else 2.5
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            return np.clip(final_pred, 1.0, 5.0)
        
        return 2.5  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def get_recommendations(self, magazin_name, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        if self.user_item_matrix is None or self.processed_data is None:
            return None
        
        try:
            user_id = self.le_magazin.transform([magazin_name])[0]
        except Exception:
            return None
        
        if user_id >= self.user_item_matrix.shape[0]:
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        n_items = self.user_item_matrix.shape[1]
        user_ratings = self.user_item_matrix[user_id]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        predictions = []
        for item_id in range(n_items):
            if user_ratings[item_id] == 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                try:
                    pred_rating = self.predict_single_rating(user_id, item_id)
                    predictions.append((item_id, pred_rating))
                except Exception:
                    continue
        
        if not predictions:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä —Ç–æ–ø-K
        predictions.sort(key=lambda x: x[1], reverse=True)
        top_items = predictions[:top_k]
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = []
        for rank, (item_id, score) in enumerate(top_items, 1):
            try:
                item_name = self.le_art.inverse_transform([item_id])[0]
                
                # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–µ
                item_info = self.processed_data[
                    self.processed_data['art_encoded'] == item_id
                ]
                
                if len(item_info) > 0:
                    info = item_info.iloc[0]
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': info['Segment'],
                        'model': info['Model'],
                        'avg_price': info['price_mean'],
                        'expected_qty': info['qty_mean']
                    }
                else:
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': 'Unknown',
                        'model': 'Unknown',
                        'avg_price': 0,
                        'expected_qty': 0
                    }
                
                recommendations.append(rec)
            except Exception:
                continue
        
        return recommendations if recommendations else None
    
    def get_all_recommendations(self, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
        if self.user_item_matrix is None:
            return None
        
        all_recommendations = {}
        for magazin_name in self.le_magazin.classes_:
            try:
                recommendations = self.get_recommendations(magazin_name, top_k)
                if recommendations:
                    all_recommendations[magazin_name] = recommendations
            except Exception:
                continue
        
        return all_recommendations if all_recommendations else None

def create_dashboard():
    st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="wide")
    
    st.title("üõçÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    st.markdown("*–ê–Ω—Å–∞–º–±–ª—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤: SVD + NMF + –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + Content-based*")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    if 'recommender' not in st.session_state:
        st.session_state.recommender = EnsembleRecommenderSystem()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.sidebar.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", 
        type=['xlsx', 'xls'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: Magazin, Datasales, Art, Describe, Model, Segment, Price, Qty"
    )
    
    if uploaded_file is not None:
        try:
            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            df = pd.read_excel(uploaded_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
                st.info("–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: Magazin, Datasales, Art, Price, Qty")
                return
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                st.metric("–ú–∞–≥–∞–∑–∏–Ω–æ–≤", df['Magazin'].nunique())
            with col3:
                st.metric("–¢–æ–≤–∞—Ä–æ–≤", df['Art'].nunique())
            with col4:
                segment_count = df['Segment'].nunique() if 'Segment' in df.columns else 0
                st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", segment_count)
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if st.sidebar.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                try:
                    with st.spinner("–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π..."):
                        metrics = st.session_state.recommender.build_ensemble_model(df)
                    
                    st.success("–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω!")
                    
                    # –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("RMSE (train)", f"{metrics['train_rmse']:.3f}")
                    with col2:
                        st.metric("RMSE (test)", f"{metrics['test_rmse']:.3f}")
                    with col3:
                        st.metric("–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['sparsity']:.1%}")
                    with col4:
                        overfitting = max(0, metrics['test_rmse'] - metrics['train_rmse'])
                        st.metric("–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ", f"{overfitting:.3f}")
                        
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {str(e)}")
                    st.info("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if st.session_state.recommender.user_item_matrix is not None:
                st.markdown("---")
                st.header("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                tab1, tab2, tab3 = st.tabs(["–î–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞", "–î–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"])
                
                with tab1:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        selected_shop = st.selectbox(
                            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:",
                            options=st.session_state.recommender.le_magazin.classes_
                        )
                    with col2:
                        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 5, 20, 10)
                    
                    if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
                        recommendations = st.session_state.recommender.get_recommendations(selected_shop, top_k)
                        
                        if recommendations:
                            rec_df = pd.DataFrame(recommendations)
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                            display_df = rec_df.copy()
                            display_df['score'] = display_df['score'].round(3)
                            display_df['avg_price'] = display_df['avg_price'].round(2)
                            display_df['expected_qty'] = display_df['expected_qty'].round(1)
                            
                            st.dataframe(display_df, use_container_width=True)
                            
                            # –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                            fig = px.bar(
                                rec_df.head(10), x='item', y='score',
                                title=f"–¢–æ–ø-10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {selected_shop}",
                                labels={'item': '–¢–æ–≤–∞—Ä', 'score': '–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥'},
                                color='score',
                                color_continuous_scale='viridis'
                            )
                            fig.update_xaxes(tickangle=45)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
                            if 'segment' in rec_df.columns:
                                segment_counts = rec_df['segment'].value_counts()
                                if len(segment_counts) > 0:
                                    fig2 = px.pie(
                                        values=segment_counts.values,
                                        names=segment_counts.index,
                                        title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                                    )
                                    st.plotly_chart(fig2, use_container_width=True)
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞")
                
                with tab2:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        batch_top_k = st.slider("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –º–∞–≥–∞–∑–∏–Ω:", 5, 15, 10)
                    with col2:
                        show_top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –¥–ª—è –æ—Ç—á–µ—Ç–∞:", 3, 10, 5)
                    
                    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"):
                        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π..."):
                            all_recs = st.session_state.recommender.get_all_recommendations(batch_top_k)
                        
                        if all_recs:
                            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                            summary_data = []
                            for shop, recs in all_recs.items():
                                for rec in recs[:show_top_n]:
                                    summary_data.append({
                                        '–ú–∞–≥–∞–∑–∏–Ω': shop,
                                        '–†–∞–Ω–≥': rec['rank'],
                                        '–¢–æ–≤–∞—Ä': rec['item'],
                                        '–ü—Ä–æ–≥–Ω–æ–∑': f"{rec['score']:.3f}",
                                        '–°–µ–≥–º–µ–Ω—Ç': rec['segment'],
                                        '–ú–æ–¥–µ–ª—å': rec['model'],
                                        '–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞': f"{rec['avg_price']:.2f}",
                                        '–û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª-–≤–æ': f"{rec['expected_qty']:.1f}"
                                    })
                            
                            if summary_data:
                                summary_df = pd.DataFrame(summary_data)
                                st.dataframe(summary_df, use_container_width=True)
                                
                                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("–í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", len(summary_data))
                                with col2:
                                    avg_score = np.mean([float(x) for x in summary_df['–ü—Ä–æ–≥–Ω–æ–∑']])
                                    st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                                with col3:
                                    unique_items = summary_df['–¢–æ–≤–∞—Ä'].nunique()
                                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", unique_items)
                                
                                # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                                @st.cache_data
                                def convert_df(df):
                                    return df.to_csv(index=False).encode('utf-8')
                                
                                csv = convert_df(summary_df)
                                st.download_button(
                                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (CSV)",
                                    data=csv,
                                    file_name='ensemble_recommendations.csv',
                                    mime='text/csv'
                                )
                            else:
                                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                with tab3:
                    if st.session_state.recommender.processed_data is not None:
                        data = st.session_state.recommender.processed_data
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
                            fig1 = px.histogram(
                                data, x='rating', bins=20,
                                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤"
                            )
                            st.plotly_chart(fig1, use_container_width=True)
                        
                        with col2:
                            # –°–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É
                            if 'Segment' in data.columns and data['Segment'].nunique() > 1:
                                segment_rating = data.groupby('Segment')['rating'].mean().sort_values(ascending=False)
                                fig2 = px.bar(
                                    x=segment_rating.index, y=segment_rating.values,
                                    title="–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                                )
                                st.plotly_chart(fig2, use_container_width=True)
                            else:
                                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º")
                        
                        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                        numeric_cols = ['qty_sum', 'revenue_sum', 'price_mean', 'freq', 'rating']
                        available_cols = [col for col in numeric_cols if col in data.columns]
                        
                        if len(available_cols) > 1:
                            corr_matrix = data[available_cols].corr()
                            
                            fig3 = px.imshow(
                                corr_matrix, 
                                title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏",
                                aspect="auto",
                                color_continuous_scale='RdBu'
                            )
                            st.plotly_chart(fig3, use_container_width=True)
                        else:
                            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                    else:
                        st.info("–î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–Ω–∞—á–∞–ª–∞.")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            st.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
            if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                st.exception(e)
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        
        # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        st.markdown("### üìã –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        example_data = {
            'Magazin': ['Shop_A', 'Shop_B', 'Shop_A', 'Shop_C'],
            'Datasales': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18'],
            'Art': ['Item_001', 'Item_002', 'Item_003', 'Item_001'],
            'Describe': ['–û–ø–∏—Å–∞–Ω–∏–µ 1', '–û–ø–∏—Å–∞–Ω–∏–µ 2', '–û–ø–∏—Å–∞–Ω–∏–µ 3', '–û–ø–∏—Å–∞–Ω–∏–µ 1'],
            'Model': ['Model_X', 'Model_Y', 'Model_Z', 'Model_X'],
            'Segment': ['Electronics', 'Clothing', 'Electronics', 'Electronics'],
            'Price': [100, 50, 150, 105],
            'Qty': [2, 1, 3, 1],
            'Sum': [200, 50, 450, 105]
        }
        example_df = pd.DataFrame(example_data)
        st.dataframe(example_df, use_container_width=True)
        
        st.markdown("### üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:")
        st.markdown("""
        - **SVD**: –ú–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        - **NMF**: –ù–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏  
        - **Item-based CF**: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
        - **Content-based**: –£—á–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ Random Forest
        - **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
        """)
        
        st.markdown("### ‚ö†Ô∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∞–Ω–Ω—ã–º:")
        st.markdown("""
        - **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏**: Magazin, Datasales, Art, Price, Qty
        - **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏**: Describe, Model, Segment (–±—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã 'Unknown' –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç)
        - **–§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã**: –õ—é–±–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
        - **–ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ**: Price –∏ Qty –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
        - **–ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö**: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–µ –º–µ–Ω–µ–µ 100 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã
        """)

if __name__ == "__main__":
    create_dashboard()
