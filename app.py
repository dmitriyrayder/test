import streamlit as st
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD, NMF
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import plotly.express as px
import plotly.graph_objects as go
from scipy.sparse import csr_matrix
import warnings
from datetime import datetime
import logging

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnsembleRecommenderSystem:
    def __init__(self):
        self.svd_model = None
        self.nmf_model = None
        self.rf_model = None
        self.item_similarity = None
        self.user_item_matrix = None
        self.scaler = StandardScaler()
        self.le_magazin = LabelEncoder()
        self.le_art = LabelEncoder()
        self.processed_data = None
        self.feature_columns = []
        self.weights = {'svd': 0.4, 'nmf': 0.3, 'similarity': 0.2, 'content': 0.1}
        
    def parse_dates(self, df, date_column='Datasales'):
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏
        """
        df = df.copy()
        
        # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞—Ç
        date_formats = [
            '%Y-%m-%d',
            '%d.%m.%Y',
            '%d/%m/%Y',
            '%m/%d/%Y',
            '%Y/%m/%d',
            '%d-%m-%Y',
            '%m-%d-%Y',
            '%Y.%m.%d',
            '%d.%m.%y',
            '%d/%m/%y',
            '%m/%d/%y',
            '%y/%m/%d',
            '%d-%m-%y',
            '%m-%d-%y'
        ]
        
        if date_column not in df.columns:
            logger.error(f"–ö–æ–ª–æ–Ω–∫–∞ {date_column} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
            raise ValueError(f"–ö–æ–ª–æ–Ω–∫–∞ {date_column} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º pandas.to_datetime —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º
        try:
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce', dayfirst=True)
            parsed_count = df[date_column].notna().sum()
            total_count = len(df)
            
            if parsed_count == total_count:
                logger.info(f"–í—Å–µ –¥–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {parsed_count}/{total_count}")
                return df
            elif parsed_count > 0:
                logger.warning(f"–ß–∞—Å—Ç–∏—á–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –¥–∞—Ç—ã: {parsed_count}/{total_count}")
        except Exception as e:
            logger.warning(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–∞—Ç –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        # –ï—Å–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –ø—Ä–æ–±—É–µ–º —Ñ–æ—Ä–º–∞—Ç—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏
        original_dates = df[date_column].copy()
        best_format = None
        best_count = 0
        
        for date_format in date_formats:
            try:
                temp_dates = pd.to_datetime(original_dates, format=date_format, errors='coerce')
                parsed_count = temp_dates.notna().sum()
                
                if parsed_count > best_count:
                    best_count = parsed_count
                    best_format = date_format
                    df[date_column] = temp_dates
                
                if parsed_count == len(df):
                    logger.info(f"–í—Å–µ –¥–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã —Å —Ñ–æ—Ä–º–∞—Ç–æ–º {date_format}: {parsed_count}/{len(df)}")
                    break
                    
            except Exception as e:
                continue
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        final_parsed = df[date_column].notna().sum()
        total = len(df)
        
        if final_parsed == 0:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –¥–∞—Ç—ã")
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–ª–æ–Ω–∫—É Datasales")
        elif final_parsed < total:
            logger.warning(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Ç–æ–ª—å–∫–æ {final_parsed} –∏–∑ {total} –¥–∞—Ç")
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
            df = df.dropna(subset=[date_column])
        else:
            logger.info(f"–£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã –≤—Å–µ {final_parsed} –¥–∞—Ç —Å —Ñ–æ—Ä–º–∞—Ç–æ–º {best_format}")
        
        return df
        
    def preprocess_data(self, df):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞—Ç"""
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
        df = self.parse_dates(df, 'Datasales')
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        initial_rows = len(df)
        df = df.dropna(subset=['Magazin', 'Art', 'Price', 'Qty'])
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df = df[df['Price'] > 0]
        df = df[df['Qty'] > 0]
        
        final_rows = len(df)
        if final_rows < initial_rows:
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {initial_rows - final_rows} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        
        if len(df) == 0:
            raise ValueError("–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        try:
            df['Month'] = df['Datasales'].dt.month
            df['Quarter'] = df['Datasales'].dt.quarter
            df['Weekday'] = df['Datasales'].dt.dayofweek
            df['DayOfMonth'] = df['Datasales'].dt.day
            df['Year'] = df['Datasales'].dt.year
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            raise
        
        # –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏
        df['Revenue'] = df['Price'] * df['Qty']
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ü–µ–Ω
        try:
            df['PriceCategory'] = pd.cut(df['Price'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ü–µ–Ω: {e}")
            df['PriceCategory'] = 'Medium'  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –≠–Ω–∫–æ–¥–∏–Ω–≥ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            df['magazin_encoded'] = self.le_magazin.fit_transform(df['Magazin'].astype(str))
            df['art_encoded'] = self.le_art.fit_transform(df['Art'].astype(str))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–Ω–∫–æ–¥–∏–Ω–≥–µ: {e}")
            raise
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω-—Ç–æ–≤–∞—Ä —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        agg_dict = {
            'Qty': ['sum', 'mean', 'count'],
            'Revenue': ['sum', 'mean'],
            'Price': ['mean', 'min', 'max'],
            'Month': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        optional_cols = ['Segment', 'Model', 'Describe']
        for col in optional_cols:
            if col in df.columns:
                agg_dict[col] = 'first'
        
        try:
            agg_data = df.groupby(['magazin_encoded', 'art_encoded', 'Magazin', 'Art']).agg(agg_dict).reset_index()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
        
        # –£–ø—Ä–æ—â–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        new_columns = ['magazin_encoded', 'art_encoded', 'Magazin', 'Art', 
                      'qty_sum', 'qty_mean', 'freq', 'revenue_sum', 'revenue_mean',
                      'price_mean', 'price_min', 'price_max', 'peak_month']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col in optional_cols:
            if col in df.columns:
                new_columns.append(col)
        
        agg_data.columns = new_columns
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        try:
            rating_components = []
            if 'qty_sum' in agg_data.columns:
                rating_components.append(np.log1p(agg_data['qty_sum']) * 0.4)
            if 'revenue_sum' in agg_data.columns:
                rating_components.append(np.log1p(agg_data['revenue_sum']) * 0.4)
            if 'freq' in agg_data.columns:
                rating_components.append(np.log1p(agg_data['freq']) * 0.2)
            
            if rating_components:
                agg_data['rating'] = sum(rating_components)
                
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞
                rating_min = agg_data['rating'].min()
                rating_max = agg_data['rating'].max()
                
                if rating_max > rating_min:
                    agg_data['rating'] = (agg_data['rating'] - rating_min) / (rating_max - rating_min) * 4 + 1
                else:
                    agg_data['rating'] = 2.5  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –µ—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            else:
                agg_data['rating'] = 2.5
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞: {e}")
            agg_data['rating'] = 2.5
        
        self.processed_data = agg_data
        logger.info(f"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(agg_data)}")
        return agg_data
    
    def create_user_item_matrix(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
        try:
            n_users = df['magazin_encoded'].nunique()
            n_items = df['art_encoded'].nunique()
            
            if n_users == 0 or n_items == 0:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã")
            
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã {n_users}x{n_items}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
            user_item_matrix = csr_matrix((df['rating'], 
                                         (df['magazin_encoded'], df['art_encoded'])), 
                                        shape=(n_users, n_items))
            
            self.user_item_matrix = user_item_matrix.toarray()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é –º–∞—Ç—Ä–∏—Ü—É
            if np.all(self.user_item_matrix == 0):
                logger.warning("–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä –ø—É—Å—Ç–∞—è")
            
            return self.user_item_matrix
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä: {e}")
            raise
    
    def prepare_content_features(self, df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
            agg_dict = {
                'price_mean': 'first',
                'qty_mean': 'first',
                'revenue_mean': 'first'
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            optional_cols = ['Segment', 'Model']
            for col in optional_cols:
                if col in df.columns:
                    agg_dict[col] = 'first'
            
            item_features = df.groupby('art_encoded').agg(agg_dict).reset_index()
            
            # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_list = [item_features[['art_encoded', 'price_mean', 'qty_mean', 'revenue_mean']]]
            
            for col in optional_cols:
                if col in item_features.columns:
                    try:
                        dummies = pd.get_dummies(item_features[col], prefix=col.lower())
                        features_list.append(dummies)
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å dummy-–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è {col}: {e}")
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = pd.concat(features_list, axis=1)
            
            self.feature_columns = [col for col in features.columns if col != 'art_encoded']
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            numeric_cols = ['price_mean', 'qty_mean', 'revenue_mean']
            existing_numeric_cols = [col for col in numeric_cols if col in features.columns]
            
            if existing_numeric_cols:
                features[existing_numeric_cols] = self.scaler.fit_transform(features[existing_numeric_cols])
            
            logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {len(features)} —Ç–æ–≤–∞—Ä–æ–≤")
            return features
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return pd.DataFrame()
    
    def build_ensemble_model(self, df, test_size=0.2):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            df = self.preprocess_data(df)
            user_item_matrix = self.create_user_item_matrix(df)
            content_features = self.prepare_content_features(df)
            
            if len(df) < 10:
                raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–º–∏–Ω–∏–º—É–º 10 –∑–∞–ø–∏—Å–µ–π)")
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)
            
            models_trained = []
            
            # 1. SVD (Matrix Factorization)
            try:
                n_components = min(50, min(user_item_matrix.shape) - 1)
                if n_components > 0:
                    self.svd_model = TruncatedSVD(n_components=n_components, random_state=42)
                    svd_matrix = self.svd_model.fit_transform(user_item_matrix)
                    models_trained.append('SVD')
                    logger.info(f"SVD –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å {n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å SVD –º–æ–¥–µ–ª—å: {e}")
            
            # 2. NMF (Non-negative Matrix Factorization)
            try:
                n_components = min(30, min(user_item_matrix.shape) - 1)
                if n_components > 0:
                    self.nmf_model = NMF(n_components=n_components, random_state=42, max_iter=500)
                    nmf_matrix = self.nmf_model.fit_transform(user_item_matrix)
                    models_trained.append('NMF')
                    logger.info(f"NMF –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å {n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å NMF –º–æ–¥–µ–ª—å: {e}")
            
            # 3. Item-based Collaborative Filtering
            try:
                self.item_similarity = cosine_similarity(user_item_matrix.T)
                models_trained.append('ItemCF')
                logger.info("Item-based CF –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å Item-based CF: {e}")
            
            # 4. Content-based Random Forest
            try:
                if len(content_features) > 0 and len(self.feature_columns) > 0:
                    rf_data = df.merge(content_features, on='art_encoded', how='left')
                    X_rf = rf_data[self.feature_columns].fillna(0)
                    y_rf = rf_data['rating']
                    
                    if len(X_rf) > 0 and len(y_rf) > 0:
                        self.rf_model = RandomForestRegressor(
                            n_estimators=100, 
                            random_state=42, 
                            max_depth=10,
                            min_samples_split=5
                        )
                        self.rf_model.fit(X_rf, y_rf)
                        models_trained.append('RandomForest')
                        logger.info("Random Forest –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å Random Forest: {e}")
            
            if not models_trained:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            try:
                train_predictions = self.predict_ratings_for_evaluation(train_data)
                test_predictions = self.predict_ratings_for_evaluation(test_data)
                
                train_rmse = np.sqrt(np.mean((train_data['rating'] - train_predictions) ** 2))
                test_rmse = np.sqrt(np.mean((test_data['rating'] - test_predictions) ** 2))
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏: {e}")
                train_rmse = test_rmse = 0.0
            
            result = {
                'train_rmse': train_rmse,
                'test_rmse': test_rmse,
                'n_users': len(df['magazin_encoded'].unique()),
                'n_items': len(df['art_encoded'].unique()),
                'sparsity': 1 - np.count_nonzero(user_item_matrix) / (user_item_matrix.shape[0] * user_item_matrix.shape[1]),
                'models_trained': models_trained
            }
            
            logger.info(f"–ê–Ω—Å–∞–º–±–ª—å –æ–±—É—á–µ–Ω. –ú–æ–¥–µ–ª–∏: {models_trained}")
            return result
            
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def predict_ratings_for_evaluation(self, test_data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""
        predictions = []
        
        for _, row in test_data.iterrows():
            try:
                user_id = row['magazin_encoded']
                item_id = row['art_encoded']
                pred = self.predict_single_rating(user_id, item_id)
                predictions.append(pred)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, —Ç–æ–≤–∞—Ä–∞ {item_id}: {e}")
                predictions.append(2.5)  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        return np.array(predictions)
    
    def predict_single_rating(self, user_id, item_id):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        predictions = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–æ–≤
        if (self.user_item_matrix is None or 
            user_id >= self.user_item_matrix.shape[0] or 
            item_id >= self.user_item_matrix.shape[1] or
            user_id < 0 or item_id < 0):
            return 2.5
        
        # SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.svd_model is not None:
            try:
                user_factors = self.svd_model.transform(self.user_item_matrix[user_id:user_id+1])
                item_factors = self.svd_model.components_[:, item_id]
                svd_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
                predictions.append(('svd', svd_pred))
            except Exception as e:
                logger.debug(f"SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        # NMF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.nmf_model is not None:
            try:
                user_factors = self.nmf_model.transform(self.user_item_matrix[user_id:user_id+1])
                item_factors = self.nmf_model.components_[:, item_id]
                nmf_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
                predictions.append(('nmf', nmf_pred))
            except Exception as e:
                logger.debug(f"NMF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        # Item similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.item_similarity is not None:
            try:
                user_ratings = self.user_item_matrix[user_id]
                similar_items = self.item_similarity[item_id]
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–æ—Ö–æ–∂–∏–º —Ç–æ–≤–∞—Ä–∞–º
                numerator = np.sum(similar_items * user_ratings)
                denominator = np.sum(np.abs(similar_items))
                
                if denominator > 0:
                    similarity_pred = numerator / denominator
                    predictions.append(('similarity', similarity_pred))
            except Exception as e:
                logger.debug(f"Similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if predictions:
            try:
                weighted_sum = sum(pred * self.weights.get(method, 0.25) for method, pred in predictions)
                total_weight = sum(self.weights.get(method, 0.25) for method, _ in predictions)
                return weighted_sum / total_weight if total_weight > 0 else 2.5
            except Exception as e:
                logger.debug(f"–ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        return 2.5  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def get_recommendations(self, magazin_name, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        if self.user_item_matrix is None:
            logger.warning("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            return None
        
        try:
            user_id = self.le_magazin.transform([magazin_name])[0]
        except ValueError:
            logger.warning(f"–ú–∞–≥–∞–∑–∏–Ω {magazin_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
            return None
        
        if user_id >= self.user_item_matrix.shape[0]:
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_id}")
            return None
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
            n_items = self.user_item_matrix.shape[1]
            user_ratings = self.user_item_matrix[user_id]
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
            predictions = []
            for item_id in range(n_items):
                if user_ratings[item_id] == 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                    pred_rating = self.predict_single_rating(user_id, item_id)
                    predictions.append((item_id, pred_rating))
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä —Ç–æ–ø-K
            predictions.sort(key=lambda x: x[1], reverse=True)
            top_items = predictions[:top_k]
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = []
            for rank, (item_id, score) in enumerate(top_items, 1):
                try:
                    item_name = self.le_art.inverse_transform([item_id])[0]
                    
                    # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–µ
                    item_info = self.processed_data[
                        self.processed_data['art_encoded'] == item_id
                    ]
                    
                    if len(item_info) > 0:
                        info = item_info.iloc[0]
                        rec = {
                            'rank': rank,
                            'item': item_name,
                            'score': score,
                            'segment': info.get('Segment', 'Unknown'),
                            'model': info.get('Model', 'Unknown'),
                            'avg_price': info.get('price_mean', 0),
                            'expected_qty': info.get('qty_mean', 0)
                        }
                    else:
                        rec = {
                            'rank': rank,
                            'item': item_name,
                            'score': score,
                            'segment': 'Unknown',
                            'model': 'Unknown',
                            'avg_price': 0,
                            'expected_qty': 0
                        }
                    
                    recommendations.append(rec)
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {item_id}: {e}")
                    continue
            
            return recommendations
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return None
    
    def get_all_recommendations(self, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
        if self.user_item_matrix is None:
            return None
        
        all_recommendations = {}
        for magazin_name in self.le_magazin.classes_:
            try:
                recommendations = self.get_recommendations(magazin_name, top_k)
                if recommendations:
                    all_recommendations[magazin_name] = recommendations
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {magazin_name}: {e}")
                continue
        
        return all_recommendations

def create_dashboard():
    st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="wide")
    
    st.title("üõçÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    st.markdown("*–ê–Ω—Å–∞–º–±–ª—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤: SVD + NMF + –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + Content-based*")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    if 'recommender' not in st.session_state:
        st.session_state.recommender = EnsembleRecommenderSystem()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.sidebar.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", 
        type=['xlsx', 'xls'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: Magazin, Datasales, Art, Price, Qty (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ) + Describe, Model, Segment (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)"
    )
    
    if uploaded_file is not None:
        try:
            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            df = pd.read_excel(uploaded_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
                st.info("üìã –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: Magazin, Datasales, Art, Price, Qty")
                return
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                st.metric("–ú–∞–≥–∞–∑–∏–Ω–æ–≤", df['Magazin'].nunique())
            with col3:
                st.metric("–¢–æ–≤–∞—Ä–æ–≤", df['Art'].nunique())
            with col4:
                if 'Segment' in df.columns:
                    st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", df['Segment'].nunique())
                else:
                    st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", "–ù/–î")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–∞—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            st.expander("üîç –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞—Ç").write(
                df['Datasales'].head(10).to_list()
            )
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if st.sidebar.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                try:
                    with st.spinner("–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π..."):
                        metrics = st.session_state.recommender.build_ensemble_model(df)
                    
                    st.success("‚úÖ –ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω!")
                    
                    # –ü–æ–∫–∞–∑–∞—Ç—å –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–∏–ª–∏—Å—å
                    if 'models_trained' in metrics:
                        models_info = ", ".join(metrics['models_trained'])
                        st.info(f"ü§ñ –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {models_info}")
                    
                    # –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("RMSE (train)", f"{metrics['train_rmse']:.3f}")
                    with col2:
                        st.metric("RMSE (test)", f"{metrics['test_rmse']:.3f}")
                    with col3:
                        st.metric("–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['sparsity']:.1%}")
                    with col4:
                        overfitting = metrics['test_rmse'] - metrics['train_rmse']
                        st.metric("–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ", f"{overfitting:.3f}")
                        
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
                    st.info("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if st.session_state.recommender.user_item_matrix is not None:
                st.markdown("---")
                st.header("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                tab1, tab2, tab3 = st.tabs(["–î–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞", "–î–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"])
                
                with tab1:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        selected_shop = st.selectbox(
                            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:",
                            options=st.session_state.recommender.le_magazin.classes_
                        )
                    with col2:
                        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 5, 20, 10)
                    
                    if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
                        try:
                            recommendations = st.session_state.recommender.get_recommendations(selected_shop, top_k)
                            
                            if recommendations:
                                rec_df = pd.DataFrame(recommendations)
                                
                                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                display_df = rec_df.copy()
                                display_df['score'] = display_df['score'].round(3)
                                display_df['avg_price'] = display_df['avg_price'].round(2)
                                display_df['expected_qty'] = display_df['expected_qty'].round(1)
                                
                                st.dataframe(display_df, use_container_width=True)
                                
                                # –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                                fig = px.bar(
                                    rec_df.head(10), x='item', y='score',
                                    title=f"–¢–æ–ø-10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {selected_shop}",
                                    labels={'item': '–¢–æ–≤–∞—Ä', 'score': '–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥'},
                                    color='score',
                                    color_continuous_scale='viridis'
                                )
                                fig.update_xaxes(tickangle=45)
                                st.plotly_chart(fig, use_container_width=True)
                                
                                # –ì—Ä–∞—Ñ–∏–∫ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
                                if 'segment' in rec_df.columns and rec_df['segment'].nunique() > 1:
                                    segment_counts = rec_df['segment'].value_counts()
                                    fig2 = px.pie(
                                        values=segment_counts.values,
                                        names=segment_counts.index,
                                        title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                                    )
                                    st.plotly_chart(fig2, use_container_width=True)
                            else:
                                st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞")
                                
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}")
                
                with tab2:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        batch_top_k = st.slider("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –º–∞–≥–∞–∑–∏–Ω:", 5, 15, 10)
                    with col2:
                        show_top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –¥–ª—è –æ—Ç—á–µ—Ç–∞:", 3, 10, 5)
                    
                    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"):
                        try:
                            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π..."):
                                all_recs = st.session_state.recommender.get_all_recommendations(batch_top_k)
                            
                            if all_recs:
                                # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                                summary_data = []
                                for shop, recs in all_recs.items():
                                    for rec in recs[:show_top_n]:
                                        summary_data.append({
                                            '–ú–∞–≥–∞–∑–∏–Ω': shop,
                                            '–†–∞–Ω–≥': rec['rank'],
                                            '–¢–æ–≤–∞—Ä': rec['item'],
                                            '–ü—Ä–æ–≥–Ω–æ–∑': f"{rec['score']:.3f}",
                                            '–°–µ–≥–º–µ–Ω—Ç': rec['segment'],
                                            '–ú–æ–¥–µ–ª—å': rec['model'],
                                            '–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞': f"{rec['avg_price']:.2f}",
                                            '–û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª-–≤–æ': f"{rec['expected_qty']:.1f}"
                                        })
                                
                                if summary_data:
                                    summary_df = pd.DataFrame(summary_data)
                                    st.dataframe(summary_df, use_container_width=True)
                                    
                                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("–í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", len(summary_data))
                                    with col2:
                                        avg_score = np.mean([float(x) for x in summary_df['–ü—Ä–æ–≥–Ω–æ–∑']])
                                        st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                                    with col3:
                                        unique_items = summary_df['–¢–æ–≤–∞—Ä'].nunique()
                                        st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", unique_items)
                                    
                                    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                                    @st.cache_data
                                    def convert_df(df):
                                        return df.to_csv(index=False, encoding='utf-8').encode('utf-8')
                                    
                                    csv = convert_df(summary_df)
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (CSV)",
                                        data=csv,
                                        file_name='ensemble_recommendations.csv',
                                        mime='text/csv'
                                    )
                                else:
                                    st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                            else:
                                st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                                
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}")
                
                with tab3:
                    if st.session_state.recommender.processed_data is not None:
                        try:
                            data = st.session_state.recommender.processed_data
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
                                fig1 = px.histogram(
                                    data, x='rating', bins=20,
                                    title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤",
                                    labels={'rating': '–†–µ–π—Ç–∏–Ω–≥', 'count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'}
                                )
                                st.plotly_chart(fig1, use_container_width=True)
                            
                            with col2:
                                # –°–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
                                if 'Segment' in data.columns:
                                    segment_rating = data.groupby('Segment')['rating'].mean().sort_values(ascending=False)
                                    fig2 = px.bar(
                                        x=segment_rating.index, y=segment_rating.values,
                                        title="–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º",
                                        labels={'x': '–°–µ–≥–º–µ–Ω—Ç', 'y': '–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥'}
                                    )
                                    st.plotly_chart(fig2, use_container_width=True)
                                else:
                                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ - —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤
                                    top_items = data.nlargest(10, 'rating')
                                    fig2 = px.bar(
                                        top_items, x='Art', y='rating',
                                        title="–¢–æ–ø-10 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É"
                                    )
                                    fig2.update_xaxes(tickangle=45)
                                    st.plotly_chart(fig2, use_container_width=True)
                            
                            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                            numeric_cols = ['qty_sum', 'revenue_sum', 'price_mean', 'freq', 'rating']
                            available_cols = [col for col in numeric_cols if col in data.columns]
                            
                            if len(available_cols) > 1:
                                corr_matrix = data[available_cols].corr()
                                
                                fig3 = px.imshow(
                                    corr_matrix, 
                                    title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏",
                                    aspect="auto",
                                    color_continuous_scale='RdBu',
                                    text_auto=True
                                )
                                st.plotly_chart(fig3, use_container_width=True)
                            
                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                            st.subheader("üìà –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥", f"{data['rating'].mean():.2f}")
                            with col2:
                                st.metric("–ú–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥", f"{data['rating'].median():.2f}")
                            with col3:
                                st.metric("–ú–∏–Ω —Ä–µ–π—Ç–∏–Ω–≥", f"{data['rating'].min():.2f}")
                            with col4:
                                st.metric("–ú–∞–∫—Å —Ä–µ–π—Ç–∏–Ω–≥", f"{data['rating'].max():.2f}")
                                
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {str(e)}")
                    else:
                        st.info("üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
        
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            st.info("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        
        # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        st.markdown("### üìã –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        example_data = {
            'Magazin': ['Shop_A', 'Shop_B', 'Shop_A', 'Shop_C'],
            'Datasales': ['2024-01-15', '16.01.2024', '17/01/2024', '2024-01-18'],
            'Art': ['Item_001', 'Item_002', 'Item_003', 'Item_001'],
            'Describe': ['–û–ø–∏—Å–∞–Ω–∏–µ 1', '–û–ø–∏—Å–∞–Ω–∏–µ 2', '–û–ø–∏—Å–∞–Ω–∏–µ 3', '–û–ø–∏—Å–∞–Ω–∏–µ 1'],
            'Model': ['Model_X', 'Model_Y', 'Model_Z', 'Model_X'],
            'Segment': ['Electronics', 'Clothing', 'Electronics', 'Electronics'],
            'Price': [100, 50, 150, 105],
            'Qty': [2, 1, 3, 1],
            'Sum': [200, 50, 450, 105]
        }
        example_df = pd.DataFrame(example_data)
        st.dataframe(example_df, use_container_width=True)
        
        st.markdown("### üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:")
        st.markdown("""
        - **–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ 14+ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞—Ç
        - **SVD**: –ú–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        - **NMF**: –ù–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏  
        - **Item-based CF**: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
        - **Content-based**: –£—á–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ Random Forest
        - **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
        - **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**: –†–æ–±—É—Å—Ç–Ω–æ—Å—Ç—å –∫ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –¥–∞–Ω–Ω—ã–º
        """)
        
        st.markdown("### üìÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç:")
        date_formats_info = """
        - `YYYY-MM-DD` (2024-01-15)
        - `DD.MM.YYYY` (15.01.2024)
        - `DD/MM/YYYY` (15/01/2024)
        - `MM/DD/YYYY` (01/15/2024)
        - `DD-MM-YYYY` (15-01-2024)
        - –ò –¥—Ä—É–≥–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        """
        st.markdown(date_formats_info)

if __name__ == "__main__":
    create_dashboard()
