import streamlit as st
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from scipy.sparse import csr_matrix
import warnings
warnings.filterwarnings('ignore')

class OptimizedRecommenderSystem:
    def __init__(self):
        self.svd_model = None
        self.rf_model = None
        self.item_similarity = None
        self.user_item_matrix = None
        self.le_magazin = LabelEncoder()
        self.le_art = LabelEncoder()
        self.scaler = StandardScaler()
        self.processed_data = None
        self.content_features = None
        self.use_rf = False
        self.weights = {'svd': 0.5, 'similarity': 0.3, 'rf': 0.2}  # –í–µ—Å–∞ —Å RF
        
    def process_datasales(self, df):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ Datasales —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏"""
        if 'Datasales' not in df.columns:
            return df
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã
        datasales_col = df['Datasales'].copy()
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        non_null_dates = datasales_col.dropna()
        if len(non_null_dates) == 0:
            return df
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
        date_formats = [
            '%Y-%m-%d',
            '%d.%m.%Y', 
            '%d/%m/%Y',
            '%m/%d/%Y',
            '%Y/%m/%d',
            '%d-%m-%Y',
            '%Y.%m.%d'
        ]
        
        parsed_dates = None
        successful_format = None
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ datetime64
        try:
            parsed_dates = pd.to_datetime(datasales_col, errors='coerce')
            if parsed_dates.notna().sum() > len(non_null_dates) * 0.8:  # –ï—Å–ª–∏ 80%+ —É—Å–ø–µ—à–Ω–æ
                df['Datasales'] = parsed_dates.astype('datetime64[ns]')
                successful_format = "auto"
        except:
            pass
        
        # –ï—Å–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º —Ñ–æ—Ä–º–∞—Ç—ã
        if successful_format is None:
            for fmt in date_formats:
                try:
                    test_dates = pd.to_datetime(non_null_dates.iloc[:min(100, len(non_null_dates))], 
                                              format=fmt, errors='coerce')
                    success_rate = test_dates.notna().sum() / len(test_dates)
                    
                    if success_rate > 0.8:  # –ï—Å–ª–∏ 80%+ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ
                        parsed_dates = pd.to_datetime(datasales_col, format=fmt, errors='coerce')
                        df['Datasales'] = parsed_dates.astype('datetime64[ns]')
                        successful_format = fmt
                        break
                except:
                    continue
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –ø—Ä–æ–±—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ timestamp
        if successful_format is None:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è timestamp'–∞–º–∏
                numeric_dates = pd.to_numeric(datasales_col, errors='coerce')
                if numeric_dates.notna().sum() > 0:
                    # –ü—Ä–æ–±—É–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Å–µ–∫—É–Ω–¥—ã –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    test_val = numeric_dates.dropna().iloc[0]
                    if test_val > 1e9:  # –ü–æ—Ö–æ–∂–µ –Ω–∞ timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                        if test_val > 1e12:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                            parsed_dates = pd.to_datetime(numeric_dates, unit='ms', errors='coerce')
                        else:  # –°–µ–∫—É–Ω–¥—ã
                            parsed_dates = pd.to_datetime(numeric_dates, unit='s', errors='coerce')
                        
                        df['Datasales'] = parsed_dates.astype('datetime64[ns]')
                        successful_format = "timestamp"
            except:
                pass
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –µ—Å–ª–∏ –¥–∞—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
        if successful_format and 'Datasales' in df.columns and df['Datasales'].dtype == 'datetime64[ns]':
            df['Month'] = df['Datasales'].dt.month
            df['Quarter'] = df['Datasales'].dt.quarter
            df['Weekday'] = df['Datasales'].dt.dayofweek
            df['DayOfMonth'] = df['Datasales'].dt.day
            df['Year'] = df['Datasales'].dt.year
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
            st.info(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ Datasales –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ (—Ñ–æ—Ä–º–∞—Ç: {successful_format})")
        else:
            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É Datasales. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
        
        return df
    
    def process_data(self, df):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df = df.copy()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ Datasales –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        df = self.process_datasales(df)
        
        # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        df = df.dropna(subset=['Magazin', 'Art', 'Price', 'Qty'])
        df = df[df['Price'] > 0]
        df = df[df['Qty'] > 0]
        
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É –¥–ª—è —ç–Ω–∫–æ–¥–∏–Ω–≥–∞
        df['Magazin'] = df['Magazin'].astype(str)
        df['Art'] = df['Art'].astype(str)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ –≤—ã—Ä—É—á–∫–∏
        df['Revenue'] = df['Price'] * df['Qty']
        
        # –≠–Ω–∫–æ–¥–∏–Ω–≥
        df['magazin_encoded'] = self.le_magazin.fit_transform(df['Magazin'])
        df['art_encoded'] = self.le_art.fit_transform(df['Art'])
        
        # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω-—Ç–æ–≤–∞—Ä
        agg_data = df.groupby(['magazin_encoded', 'art_encoded', 'Magazin', 'Art']).agg({
            'Qty': 'sum',
            'Revenue': 'sum',
            'Price': 'mean',
            'Segment': 'first',
            'Model': 'first'
        }).reset_index()
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –ø–æ–ª—è –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
        agg_data['Segment'] = agg_data['Segment'].astype(str)
        agg_data['Model'] = agg_data['Model'].astype(str)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞
        agg_data['rating'] = np.log1p(agg_data['Qty']) + np.log1p(agg_data['Revenue']) * 0.1
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –æ—Ç 1 –¥–æ 5
        min_rating = agg_data['rating'].min()
        max_rating = agg_data['rating'].max()
        if max_rating > min_rating:
            agg_data['rating'] = (agg_data['rating'] - min_rating) / (max_rating - min_rating) * 4 + 1
        else:
            agg_data['rating'] = 2.5
        
        self.processed_data = agg_data
        return agg_data
    
    def create_user_item_matrix(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä"""
        n_users = df['magazin_encoded'].nunique()
        n_items = df['art_encoded'].nunique()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
        sparse_matrix = csr_matrix((df['rating'], 
                                  (df['magazin_encoded'], df['art_encoded'])), 
                                 shape=(n_users, n_items))
        
        self.user_item_matrix = sparse_matrix
        return sparse_matrix
    
    def build_model(self, df, test_size=0.2):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –≤—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞
        df = self.process_data(df)
        user_item_matrix = self.create_user_item_matrix(df)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –ø–ª–æ—Ç–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è SVD
        dense_matrix = user_item_matrix.toarray()
        
        # SVD (Matrix Factorization)
        n_components = min(30, min(dense_matrix.shape) - 1)  # –£–º–µ–Ω—å—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        if n_components <= 0:
            n_components = 1
        
        self.svd_model = TruncatedSVD(n_components=n_components, random_state=42)
        self.svd_model.fit(dense_matrix)
        
        # Item-based Collaborative Filtering (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤)
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ—Ü–µ–Ω–æ–∫ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        item_counts = np.array(user_item_matrix.sum(axis=0))[0]
        
        if len(item_counts) > 0 and np.max(item_counts) > 0:
            top_items_mask = item_counts >= np.percentile(item_counts[item_counts > 0], 50)
            
            if np.sum(top_items_mask) > 0:
                filtered_matrix = dense_matrix[:, top_items_mask]
                if filtered_matrix.shape[1] > 1:  # –ù—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 —Ç–æ–≤–∞—Ä–∞ –¥–ª—è similarity
                    self.item_similarity = cosine_similarity(filtered_matrix.T)
                    self.top_items_indices = np.where(top_items_mask)[0]
                else:
                    self.item_similarity = None
                    self.top_items_indices = None
            else:
                if dense_matrix.shape[1] > 1:
                    self.item_similarity = cosine_similarity(dense_matrix.T)
                    self.top_items_indices = np.arange(dense_matrix.shape[1])
                else:
                    self.item_similarity = None
                    self.top_items_indices = None
        else:
            self.item_similarity = None
            self.top_items_indices = None
        
        # –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        sample_size = min(1000, len(test_data))
        if sample_size > 0:
            test_sample = test_data.sample(n=sample_size, random_state=42)
            
            predictions = []
            actuals = []
            
            for _, row in test_sample.iterrows():
                pred = self.predict_single_rating(row['magazin_encoded'], row['art_encoded'])
                predictions.append(pred)
                actuals.append(row['rating'])
            
            if len(predictions) > 0:
                rmse = np.sqrt(np.mean((np.array(actuals) - np.array(predictions)) ** 2))
            else:
                rmse = 0.0
        else:
            rmse = 0.0
        
        return {
            'rmse': rmse,
            'n_users': len(df['magazin_encoded'].unique()),
            'n_items': len(df['art_encoded'].unique()),
            'sparsity': 1 - user_item_matrix.nnz / (user_item_matrix.shape[0] * user_item_matrix.shape[1])
        }
    
    def predict_single_rating(self, user_id, item_id):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞"""
        predictions = []
        dense_matrix = self.user_item_matrix.toarray()
        
        # SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.svd_model and user_id < dense_matrix.shape[0] and item_id < dense_matrix.shape[1]:
            try:
                user_factors = self.svd_model.transform(dense_matrix[user_id:user_id+1])
                item_factors = self.svd_model.components_[:, item_id]
                svd_pred = np.dot(user_factors[0], item_factors)
                predictions.append(('svd', svd_pred))
            except:
                pass
        
        # Item similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤)
        if (self.item_similarity is not None and 
            hasattr(self, 'top_items_indices') and 
            self.top_items_indices is not None and
            user_id < dense_matrix.shape[0] and 
            item_id in self.top_items_indices):
            
            try:
                item_idx_in_filtered = np.where(self.top_items_indices == item_id)[0]
                if len(item_idx_in_filtered) > 0:
                    item_idx = item_idx_in_filtered[0]
                    user_ratings = dense_matrix[user_id, self.top_items_indices]
                    similar_items = self.item_similarity[item_idx]
                    
                    # –ü—Ä–æ—Å—Ç–æ–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
                    mask = user_ratings > 0
                    if np.sum(mask) > 0:
                        numerator = np.sum(similar_items[mask] * user_ratings[mask])
                        denominator = np.sum(np.abs(similar_items[mask]))
                        
                        if denominator > 0:
                            similarity_pred = numerator / denominator
                            predictions.append(('similarity', similarity_pred))
            except:
                pass
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if predictions:
            weighted_sum = sum(pred * self.weights[method] for method, pred in predictions)
            total_weight = sum(self.weights[method] for method, _ in predictions)
            return weighted_sum / total_weight if total_weight > 0 else 2.5
        
        return 2.5
    
    def get_recommendations(self, magazin_name, top_k=10):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        if self.user_item_matrix is None:
            return None
        
        try:
            user_id = self.le_magazin.transform([magazin_name])[0]
        except:
            return None
        
        dense_matrix = self.user_item_matrix.toarray()
        if user_id >= dense_matrix.shape[0]:
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ—â–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª
        user_ratings = dense_matrix[user_id]
        unrated_items = np.where(user_ratings == 0)[0]
        
        if len(unrated_items) == 0:
            return []
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø–æ–∫—É–ø–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        predictions = []
        for item_id in unrated_items:
            pred_rating = self.predict_single_rating(user_id, item_id)
            predictions.append((item_id, pred_rating))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä —Ç–æ–ø-K
        predictions.sort(key=lambda x: x[1], reverse=True)
        top_items = predictions[:top_k]
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        recommendations = []
        for rank, (item_id, score) in enumerate(top_items, 1):
            try:
                item_name = self.le_art.inverse_transform([item_id])[0]
                
                # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–µ
                item_info = self.processed_data[self.processed_data['art_encoded'] == item_id]
                
                if len(item_info) > 0:
                    info = item_info.iloc[0]
                    recommendations.append({
                        'rank': rank,
                        'item': item_name,
                        'score': round(score, 3),
                        'segment': info['Segment'],
                        'model': info['Model'],
                        'avg_price': round(info['Price'], 2),
                        'total_qty': int(info['Qty'])
                    })
                else:
                    recommendations.append({
                        'rank': rank,
                        'item': item_name,
                        'score': round(score, 3),
                        'segment': 'Unknown',
                        'model': 'Unknown',
                        'avg_price': 0,
                        'total_qty': 0
                    })
            except:
                continue
        
        return recommendations
    
    def get_all_recommendations(self, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
        if self.user_item_matrix is None:
            return None
        
        all_recommendations = {}
        for magazin_name in self.le_magazin.classes_:
            recommendations = self.get_recommendations(magazin_name, top_k)
            if recommendations:
                all_recommendations[magazin_name] = recommendations
        
        return all_recommendations

def create_dashboard():
    st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="wide")
    
    st.title("üõçÔ∏è –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞")
    st.markdown("*SVD + Item-based –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è*")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    if 'recommender' not in st.session_state:
        st.session_state.recommender = OptimizedRecommenderSystem()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.sidebar.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", 
        type=['xlsx', 'xls'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: Magazin, Art, Segment, Model, Price, Qty"
    )
    
    if uploaded_file is not None:
        try:
            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            df = pd.read_excel(uploaded_file)
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            st.info("üîÑ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–∞–º
            if 'Price' in df.columns:
                df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
            if 'Qty' in df.columns:
                df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce')
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤
            df = df.dropna(subset=['Price', 'Qty'])
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['Magazin', 'Art', 'Segment', 'Model', 'Price', 'Qty']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
                return
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
            if len(df) == 0:
                st.error("–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.")
                return
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                st.metric("–ú–∞–≥–∞–∑–∏–Ω–æ–≤", df['Magazin'].nunique())
            with col3:
                st.metric("–¢–æ–≤–∞—Ä–æ–≤", df['Art'].nunique())
            with col4:
                st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", df['Segment'].nunique())
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if st.sidebar.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."):
                    metrics = st.session_state.recommender.build_model(df)
                
                st.success("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("RMSE", f"{metrics['rmse']:.3f}")
                with col2:
                    st.metric("–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['sparsity']:.1%}")
                with col3:
                    st.metric("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ x –¢–æ–≤–∞—Ä—ã", f"{metrics['n_users']} x {metrics['n_items']}")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if st.session_state.recommender.user_item_matrix is not None:
                st.markdown("---")
                st.header("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                tab1, tab2 = st.tabs(["–î–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞", "–î–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"])
                
                with tab1:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        selected_shop = st.selectbox(
                            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:",
                            options=st.session_state.recommender.le_magazin.classes_
                        )
                    with col2:
                        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 5, 20, 10)
                    
                    if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
                        recommendations = st.session_state.recommender.get_recommendations(selected_shop, top_k)
                        
                        if recommendations:
                            rec_df = pd.DataFrame(recommendations)
                            st.dataframe(rec_df, use_container_width=True)
                            
                            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                avg_score = rec_df['score'].mean()
                                st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                            with col2:
                                top_segment = rec_df['segment'].mode().iloc[0] if len(rec_df) > 0 else "N/A"
                                st.metric("–¢–æ–ø —Å–µ–≥–º–µ–Ω—Ç", top_segment)
                            with col3:
                                avg_price = rec_df['avg_price'].mean()
                                st.metric("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", f"{avg_price:.2f}")
                        else:
                            st.info("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞")
                
                with tab2:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        batch_top_k = st.slider("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –º–∞–≥–∞–∑–∏–Ω:", 5, 15, 10)
                    with col2:
                        show_top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –¥–ª—è –æ—Ç—á–µ—Ç–∞:", 3, 10, 5)
                    
                    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö"):
                        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π..."):
                            all_recs = st.session_state.recommender.get_all_recommendations(batch_top_k)
                        
                        if all_recs:
                            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                            summary_data = []
                            for shop, recs in all_recs.items():
                                for rec in recs[:show_top_n]:
                                    summary_data.append({
                                        '–ú–∞–≥–∞–∑–∏–Ω': shop,
                                        '–†–∞–Ω–≥': rec['rank'],
                                        '–¢–æ–≤–∞—Ä': rec['item'],
                                        '–ü—Ä–æ–≥–Ω–æ–∑': rec['score'],
                                        '–°–µ–≥–º–µ–Ω—Ç': rec['segment'],
                                        '–ú–æ–¥–µ–ª—å': rec['model'],
                                        '–¶–µ–Ω–∞': rec['avg_price'],
                                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': rec['total_qty']
                                    })
                            
                            summary_df = pd.DataFrame(summary_data)
                            st.dataframe(summary_df, use_container_width=True)
                            
                            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("–í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", len(summary_data))
                            with col2:
                                avg_score = summary_df['–ü—Ä–æ–≥–Ω–æ–∑'].mean()
                                st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                            with col3:
                                unique_items = summary_df['–¢–æ–≤–∞—Ä'].nunique()
                                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", unique_items)
                            
                            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            @st.cache_data
                            def convert_df(df):
                                return df.to_csv(index=False, encoding='utf-8').encode('utf-8')
                            
                            csv = convert_df(summary_df)
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (CSV)",
                                data=csv,
                                file_name='recommendations.csv',
                                mime='text/csv'
                            )
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            st.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        
        # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        st.markdown("### üìã –¢—Ä–µ–±—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:")
        st.markdown("- **Magazin** - –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞")
        st.markdown("- **Art** - –∫–æ–¥/–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞") 
        st.markdown("- **Segment** - —Å–µ–≥–º–µ–Ω—Ç —Ç–æ–≤–∞—Ä–∞")
        st.markdown("- **Model** - –º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞")
        st.markdown("- **Price** - —Ü–µ–Ω–∞")
        st.markdown("- **Qty** - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ")

if __name__ == "__main__":
    create_dashboard()
