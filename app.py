import streamlit as st
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import plotly.express as px
from scipy.sparse import csr_matrix
import warnings
warnings.filterwarnings('ignore')

class RecommenderSystem:
    def __init__(self):
        self.svd_model = None
        self.item_similarity = None
        self.rf_model = None
        self.user_item_matrix = None
        self.le_magazin = LabelEncoder()
        self.le_art = LabelEncoder()
        self.processed_data = None
        self.weights = {'svd': 0.4, 'similarity': 0.4, 'content': 0.2}
        
    def preprocess_data(self, df, selected_segments=None):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"""
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
        if selected_segments and 'Segment' in df.columns:
            df = df[df['Segment'].isin(selected_segments)]
            if len(df) == 0:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = df.dropna(subset=['Magazin', 'Art', 'Price', 'Qty'])
        df['Datasales'] = pd.to_datetime(df['Datasales'], errors='coerce')
        df = df.dropna(subset=['Datasales'])
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df['Revenue'] = df['Price'] * df['Qty']
        df['Month'] = df['Datasales'].dt.month
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for col in ['Segment', 'Model', 'Describe']:
            if col not in df.columns:
                df[col] = 'Unknown'
            else:
                df[col] = df[col].fillna('Unknown')
        
        # –≠–Ω–∫–æ–¥–∏–Ω–≥
        df['magazin_encoded'] = self.le_magazin.fit_transform(df['Magazin'].astype(str))
        df['art_encoded'] = self.le_art.fit_transform(df['Art'].astype(str))
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω-—Ç–æ–≤–∞—Ä (–Ω–∞ –æ—Å–Ω–æ–≤–µ —à—Ç—É—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂)
        agg_data = df.groupby(['magazin_encoded', 'art_encoded', 'Magazin', 'Art']).agg({
            'Qty': ['sum', 'mean', 'count'],
            'Revenue': 'sum',
            'Price': 'mean',
            'Segment': 'first',
            'Model': 'first'
        }).reset_index()
        
        # –£–ø—Ä–æ—â–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        agg_data.columns = ['magazin_encoded', 'art_encoded', 'Magazin', 'Art', 
                           'qty_sum', 'qty_mean', 'freq', 'revenue_sum', 'price_mean',
                           'Segment', 'Model']
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—Ç—É—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂
        agg_data['qty_sum'] = np.maximum(agg_data['qty_sum'], 1)
        agg_data['freq'] = np.maximum(agg_data['freq'], 1)
        
        # –†–µ–π—Ç–∏–Ω–≥ = –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã
        agg_data['rating'] = (
            np.log1p(agg_data['qty_sum']) * 0.7 +  # –ë–æ–ª—å—à–∏–π –≤–µ—Å –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            np.log1p(agg_data['freq']) * 0.3
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω 1-5
        rating_min, rating_max = agg_data['rating'].min(), agg_data['rating'].max()
        if rating_max > rating_min:
            agg_data['rating'] = (agg_data['rating'] - rating_min) / (rating_max - rating_min) * 4 + 1
        else:
            agg_data['rating'] = 2.5
        
        self.processed_data = agg_data
        return agg_data
    
    def create_user_item_matrix(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä"""
        n_users = df['magazin_encoded'].nunique()
        n_items = df['art_encoded'].nunique()
        
        user_item_matrix = csr_matrix(
            (df['rating'], (df['magazin_encoded'], df['art_encoded'])), 
            shape=(n_users, n_items)
        )
        
        self.user_item_matrix = user_item_matrix.toarray()
        return self.user_item_matrix
    
    def build_model(self, df, selected_segments=None):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        df = self.preprocess_data(df, selected_segments)
        if len(df) < 10:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º—É–º 10 –∑–∞–ø–∏—Å–µ–π)")
        
        user_item_matrix = self.create_user_item_matrix(df)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)
        
        # 1. SVD
        n_components = min(30, min(user_item_matrix.shape) - 1)
        if n_components > 0:
            self.svd_model = TruncatedSVD(n_components=n_components, random_state=42)
            self.svd_model.fit(user_item_matrix)
        
        # 2. Item Similarity
        if user_item_matrix.shape[1] > 1:
            self.item_similarity = cosine_similarity(user_item_matrix.T)
        
        # 3. Content-based Random Forest
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            item_features = df.groupby('art_encoded').agg({
                'price_mean': 'first',
                'qty_mean': 'first',
                'Segment': 'first'
            }).reset_index()
            
            # One-hot encoding –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            segment_dummies = pd.get_dummies(item_features['Segment'], prefix='segment')
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_df = pd.concat([
                item_features[['art_encoded', 'price_mean', 'qty_mean']],
                segment_dummies
            ], axis=1)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RF
            rf_data = df.merge(features_df, on='art_encoded', how='left')
            feature_cols = [col for col in features_df.columns if col != 'art_encoded']
            
            X = rf_data[feature_cols].fillna(0)
            y = rf_data['rating']
            
            self.rf_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
            self.rf_model.fit(X, y)
            self.feature_columns = feature_cols
            self.content_features = features_df
            
        except Exception as e:
            st.warning(f"Content-based –º–æ–¥–µ–ª—å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞: {e}")
            self.rf_model = None
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        train_pred = self.predict_batch(train_data)
        test_pred = self.predict_batch(test_data)
        
        train_rmse = np.sqrt(np.mean((train_data['rating'] - train_pred) ** 2))
        test_rmse = np.sqrt(np.mean((test_data['rating'] - test_pred) ** 2))
        
        return {
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'n_users': len(df['magazin_encoded'].unique()),
            'n_items': len(df['art_encoded'].unique()),
            'sparsity': 1 - np.count_nonzero(user_item_matrix) / user_item_matrix.size
        }
    
    def predict_batch(self, data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–∞—Ç—á–∞ –¥–∞–Ω–Ω—ã—Ö"""
        predictions = []
        for _, row in data.iterrows():
            pred = self.predict_rating(row['magazin_encoded'], row['art_encoded'])
            predictions.append(pred)
        return np.array(predictions)
    
    def predict_rating(self, user_id, item_id):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞"""
        if (user_id >= self.user_item_matrix.shape[0] or 
            item_id >= self.user_item_matrix.shape[1]):
            return 2.5
        
        predictions = []
        
        # SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.svd_model is not None:
            try:
                user_vec = self.svd_model.transform(self.user_item_matrix[user_id:user_id+1])
                item_vec = self.svd_model.components_[:, item_id]
                svd_pred = np.dot(user_vec, item_vec.reshape(-1, 1))[0, 0]
                predictions.append(('svd', svd_pred))
            except:
                pass
        
        # Similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.item_similarity is not None:
            try:
                user_ratings = self.user_item_matrix[user_id]
                similar_items = self.item_similarity[item_id]
                
                numerator = np.sum(similar_items * user_ratings)
                denominator = np.sum(np.abs(similar_items))
                
                if denominator > 1e-8:
                    sim_pred = numerator / denominator
                    predictions.append(('similarity', sim_pred))
            except:
                pass
        
        # Content –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.rf_model is not None:
            try:
                item_data = self.content_features[
                    self.content_features['art_encoded'] == item_id
                ]
                if len(item_data) > 0:
                    X = item_data[self.feature_columns].fillna(0)
                    content_pred = self.rf_model.predict(X)[0]
                    predictions.append(('content', content_pred))
            except:
                pass
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if predictions:
            weighted_sum = sum(pred * self.weights.get(method, 0.33) for method, pred in predictions)
            total_weight = sum(self.weights.get(method, 0.33) for method, _ in predictions)
            return np.clip(weighted_sum / total_weight, 1.0, 5.0)
        
        return 2.5
    
    def get_recommendations(self, magazin_name, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        try:
            user_id = self.le_magazin.transform([magazin_name])[0]
        except:
            return None
        
        if user_id >= self.user_item_matrix.shape[0]:
            return None
        
        user_ratings = self.user_item_matrix[user_id]
        predictions = []
        
        for item_id in range(self.user_item_matrix.shape[1]):
            if user_ratings[item_id] == 0:  # –¢–æ–ª—å–∫–æ –Ω–µ–æ—Ü–µ–Ω–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
                pred = self.predict_rating(user_id, item_id)
                predictions.append((item_id, pred))
        
        if not predictions:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä —Ç–æ–ø-K
        predictions.sort(key=lambda x: x[1], reverse=True)
        top_items = predictions[:top_k]
        
        recommendations = []
        for rank, (item_id, score) in enumerate(top_items, 1):
            try:
                item_name = self.le_art.inverse_transform([item_id])[0]
                item_info = self.processed_data[
                    self.processed_data['art_encoded'] == item_id
                ]
                
                if len(item_info) > 0:
                    info = item_info.iloc[0]
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': info['Segment'],
                        'model': info['Model'],
                        'avg_price': info['price_mean'],
                        'expected_qty': info['qty_mean']
                    }
                else:
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': 'Unknown',
                        'model': 'Unknown',
                        'avg_price': 0,
                        'expected_qty': 0
                    }
                
                recommendations.append(rec)
            except:
                continue
        
        return recommendations

def create_dashboard():
    st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="wide")
    
    st.title("üõçÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞")
    st.markdown("*–ê–Ω—Å–∞–º–±–ª—å: SVD + –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + Content-based*")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    if 'recommender' not in st.session_state:
        st.session_state.recommender = RecommenderSystem()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.sidebar.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])
    
    if uploaded_file is not None:
        try:
            df = pd.read_excel(uploaded_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['Magazin', 'Datasales', 'Art', 'Price', 'Qty']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
                return
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                st.metric("–ú–∞–≥–∞–∑–∏–Ω–æ–≤", df['Magazin'].nunique())
            with col3:
                st.metric("–¢–æ–≤–∞—Ä–æ–≤", df['Art'].nunique())
            with col4:
                segments = df['Segment'].nunique() if 'Segment' in df.columns else 0
                st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", segments)
            
            # –§–∏–ª—å—Ç—Ä —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            segment_filter = None
            if 'Segment' in df.columns and df['Segment'].nunique() > 1:
                st.sidebar.header("üéØ –§–∏–ª—å—Ç—Ä —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                all_segments = df['Segment'].dropna().unique().tolist()
                selected_segments = st.sidebar.multiselect(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç—ã:",
                    options=all_segments,
                    default=all_segments,
                    help="–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
                )
                
                if selected_segments != all_segments:
                    segment_filter = selected_segments
                    filtered_count = len(df[df['Segment'].isin(selected_segments)])
                    st.sidebar.info(f"–ó–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {filtered_count}")
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if st.sidebar.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                try:
                    with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."):
                        metrics = st.session_state.recommender.build_model(df, segment_filter)
                    
                    st.success("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("RMSE (train)", f"{metrics['train_rmse']:.3f}")
                    with col2:
                        st.metric("RMSE (test)", f"{metrics['test_rmse']:.3f}")
                    with col3:
                        st.metric("–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['sparsity']:.1%}")
                    with col4:
                        overfitting = max(0, metrics['test_rmse'] - metrics['train_rmse'])
                        st.metric("–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ", f"{overfitting:.3f}")
                        
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞: {str(e)}")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if st.session_state.recommender.user_item_matrix is not None:
                st.markdown("---")
                st.header("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                tab1, tab2, tab3 = st.tabs(["–û–¥–∏–Ω–æ—á–Ω—ã–µ", "–ú–∞—Å—Å–æ–≤—ã–µ", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"])
                
                with tab1:
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        selected_shop = st.selectbox(
                            "–ú–∞–≥–∞–∑–∏–Ω:",
                            options=st.session_state.recommender.le_magazin.classes_
                        )
                    with col2:
                        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:", 5, 20, 10)
                    
                    if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
                        recs = st.session_state.recommender.get_recommendations(selected_shop, top_k)
                        
                        if recs:
                            rec_df = pd.DataFrame(recs)
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                            display_df = rec_df.copy()
                            display_df['score'] = display_df['score'].round(3)
                            display_df['avg_price'] = display_df['avg_price'].round(2)
                            display_df['expected_qty'] = display_df['expected_qty'].round(1)
                            
                            st.dataframe(display_df, use_container_width=True)
                            
                            # –ì—Ä–∞—Ñ–∏–∫
                            fig = px.bar(
                                rec_df.head(10), x='item', y='score',
                                title=f"–¢–æ–ø-10 –¥–ª—è {selected_shop}",
                                color='score',
                                color_continuous_scale='viridis'
                            )
                            fig.update_xaxes(tickangle=45)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                
                with tab2:
                    col1, col2 = st.columns(2)
                    with col1:
                        batch_k = st.slider("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –º–∞–≥–∞–∑–∏–Ω:", 5, 15, 8)
                    with col2:
                        show_top = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å –≤ –æ—Ç—á–µ—Ç–µ:", 3, 10, 5)
                    
                    if st.button("–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –≤—Å–µ—Ö"):
                        summary_data = []
                        
                        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è..."):
                            for shop in st.session_state.recommender.le_magazin.classes_:
                                recs = st.session_state.recommender.get_recommendations(shop, batch_k)
                                if recs:
                                    for rec in recs[:show_top]:
                                        summary_data.append({
                                            '–ú–∞–≥–∞–∑–∏–Ω': shop,
                                            '–†–∞–Ω–≥': rec['rank'],
                                            '–¢–æ–≤–∞—Ä': rec['item'],
                                            '–ü—Ä–æ–≥–Ω–æ–∑': f"{rec['score']:.3f}",
                                            '–°–µ–≥–º–µ–Ω—Ç': rec['segment'],
                                            '–¶–µ–Ω–∞': f"{rec['avg_price']:.2f}"
                                        })
                        
                        if summary_data:
                            summary_df = pd.DataFrame(summary_data)
                            st.dataframe(summary_df, use_container_width=True)
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("–í—Å–µ–≥–æ", len(summary_data))
                            with col2:
                                avg_score = np.mean([float(x) for x in summary_df['–ü—Ä–æ–≥–Ω–æ–∑']])
                                st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                            with col3:
                                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", summary_df['–¢–æ–≤–∞—Ä'].nunique())
                            
                            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
                            csv = summary_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                "üì• –°–∫–∞—á–∞—Ç—å CSV",
                                data=csv,
                                file_name='recommendations.csv',
                                mime='text/csv'
                            )
                
                with tab3:
                    if st.session_state.recommender.processed_data is not None:
                        data = st.session_state.recommender.processed_data
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π histogram
                            fig1 = px.histogram(
                                data, x='rating', nbins=20,
                                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤"
                            )
                            st.plotly_chart(fig1, use_container_width=True)
                        
                        with col2:
                            if 'Segment' in data.columns and data['Segment'].nunique() > 1:
                                segment_rating = data.groupby('Segment')['rating'].mean().sort_values(ascending=False)
                                fig2 = px.bar(
                                    x=segment_rating.index, y=segment_rating.values,
                                    title="–†–µ–π—Ç–∏–Ω–≥ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                                )
                                st.plotly_chart(fig2, use_container_width=True)
                        
                        # –¢–æ–ø —Ç–æ–≤–∞—Ä—ã –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º
                        top_items = data.nlargest(10, 'qty_sum')[['Art', 'qty_sum', 'Segment']]
                        fig3 = px.bar(
                            top_items, x='Art', y='qty_sum', color='Segment',
                            title="–¢–æ–ø-10 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º"
                        )
                        fig3.update_xaxes(tickangle=45)
                        st.plotly_chart(fig3, use_container_width=True)
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {str(e)}")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª")
        
        # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
        st.markdown("### üìã –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:")
        example = pd.DataFrame({
            'Magazin': ['Shop_A', 'Shop_B', 'Shop_A'],
            'Datasales': ['2024-01-15', '2024-01-16', '2024-01-17'],
            'Art': ['Item_001', 'Item_002', 'Item_001'],
            'Segment': ['Electronics', 'Clothing', 'Electronics'],
            'Price': [100, 50, 100],
            'Qty': [2, 1, 3]
        })
        st.dataframe(example, use_container_width=True)

if __name__ == "__main__":
    create_dashboard()
