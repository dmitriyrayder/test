import streamlit as st
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD, NMF
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import plotly.express as px
import plotly.graph_objects as go
from scipy.sparse import csr_matrix
import warnings
warnings.filterwarnings('ignore')

class EnsembleRecommenderSystem:
    def __init__(self):
        self.svd_model = None
        self.nmf_model = None
        self.rf_model = None
        self.item_similarity = None
        self.user_item_matrix = None
        self.scaler = StandardScaler()
        self.le_magazin = LabelEncoder()
        self.le_art = LabelEncoder()
        self.processed_data = None
        self.feature_columns = []
        self.weights = {'svd': 0.4, 'nmf': 0.3, 'similarity': 0.2, 'content': 0.1}
        
    def preprocess_data(self, df):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        df = df.copy()
        df['Datasales'] = pd.to_datetime(df['Datasales'], errors='coerce')
        df = df.dropna(subset=['Magazin', 'Art', 'Price', 'Qty'])
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df['Month'] = df['Datasales'].dt.month
        df['Quarter'] = df['Datasales'].dt.quarter
        df['Weekday'] = df['Datasales'].dt.dayofweek
        df['DayOfMonth'] = df['Datasales'].dt.day
        
        # –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏
        df['Revenue'] = df['Price'] * df['Qty']
        df['PriceCategory'] = pd.cut(df['Price'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])
        
        # –≠–Ω–∫–æ–¥–∏–Ω–≥
        df['magazin_encoded'] = self.le_magazin.fit_transform(df['Magazin'])
        df['art_encoded'] = self.le_art.fit_transform(df['Art'])
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –º–∞–≥–∞–∑–∏–Ω-—Ç–æ–≤–∞—Ä
        agg_data = df.groupby(['magazin_encoded', 'art_encoded', 'Magazin', 'Art']).agg({
            'Qty': ['sum', 'mean', 'count'],
            'Revenue': ['sum', 'mean'],
            'Price': ['mean', 'min', 'max'],
            'Month': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],
            'Segment': 'first',
            'Model': 'first',
            'Describe': 'first'
        }).reset_index()
        
        # –£–ø—Ä–æ—â–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        agg_data.columns = ['magazin_encoded', 'art_encoded', 'Magazin', 'Art', 
                           'qty_sum', 'qty_mean', 'freq', 'revenue_sum', 'revenue_mean',
                           'price_mean', 'price_min', 'price_max', 'peak_month',
                           'Segment', 'Model', 'Describe']
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
        agg_data['rating'] = (
            np.log1p(agg_data['qty_sum']) * 0.4 +
            np.log1p(agg_data['revenue_sum']) * 0.4 +
            np.log1p(agg_data['freq']) * 0.2
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞
        agg_data['rating'] = (agg_data['rating'] - agg_data['rating'].min()) / (agg_data['rating'].max() - agg_data['rating'].min()) * 4 + 1
        
        self.processed_data = agg_data
        return agg_data
    
    def create_user_item_matrix(self, df):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–≤–∞—Ä"""
        n_users = df['magazin_encoded'].nunique()
        n_items = df['art_encoded'].nunique()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
        user_item_matrix = csr_matrix((df['rating'], 
                                     (df['magazin_encoded'], df['art_encoded'])), 
                                    shape=(n_users, n_items))
        
        self.user_item_matrix = user_item_matrix.toarray()
        return self.user_item_matrix
    
    def prepare_content_features(self, df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
        item_features = df.groupby('art_encoded').agg({
            'price_mean': 'first',
            'Segment': 'first',
            'Model': 'first',
            'qty_mean': 'first',
            'revenue_mean': 'first'
        }).reset_index()
        
        # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        segment_dummies = pd.get_dummies(item_features['Segment'], prefix='segment')
        model_dummies = pd.get_dummies(item_features['Model'], prefix='model')
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = pd.concat([
            item_features[['art_encoded', 'price_mean', 'qty_mean', 'revenue_mean']],
            segment_dummies,
            model_dummies
        ], axis=1)
        
        self.feature_columns = [col for col in features.columns if col != 'art_encoded']
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        numeric_cols = ['price_mean', 'qty_mean', 'revenue_mean']
        features[numeric_cols] = self.scaler.fit_transform(features[numeric_cols])
        
        return features
    
    def build_ensemble_model(self, df, test_size=0.2):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        df = self.preprocess_data(df)
        user_item_matrix = self.create_user_item_matrix(df)
        content_features = self.prepare_content_features(df)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        train_data, test_data = train_test_split(df, test_size=test_size, random_state=42)
        
        # 1. SVD (Matrix Factorization)
        self.svd_model = TruncatedSVD(n_components=min(50, min(user_item_matrix.shape)), random_state=42)
        svd_matrix = self.svd_model.fit_transform(user_item_matrix)
        
        # 2. NMF (Non-negative Matrix Factorization)
        self.nmf_model = NMF(n_components=min(30, min(user_item_matrix.shape)), random_state=42, max_iter=500)
        nmf_matrix = self.nmf_model.fit_transform(user_item_matrix)
        
        # 3. Item-based Collaborative Filtering
        self.item_similarity = cosine_similarity(user_item_matrix.T)
        
        # 4. Content-based Random Forest
        if len(content_features) > 0:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RF
            rf_data = df.merge(content_features, on='art_encoded', how='left')
            X_rf = rf_data[self.feature_columns].fillna(0)
            y_rf = rf_data['rating']
            
            self.rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
            self.rf_model.fit(X_rf, y_rf)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        train_predictions = self.predict_ratings_for_evaluation(train_data)
        test_predictions = self.predict_ratings_for_evaluation(test_data)
        
        train_rmse = np.sqrt(np.mean((train_data['rating'] - train_predictions) ** 2))
        test_rmse = np.sqrt(np.mean((test_data['rating'] - test_predictions) ** 2))
        
        return {
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'n_users': len(df['magazin_encoded'].unique()),
            'n_items': len(df['art_encoded'].unique()),
            'sparsity': 1 - np.count_nonzero(user_item_matrix) / (user_item_matrix.shape[0] * user_item_matrix.shape[1])
        }
    
    def predict_ratings_for_evaluation(self, test_data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""
        predictions = []
        
        for _, row in test_data.iterrows():
            user_id = row['magazin_encoded']
            item_id = row['art_encoded']
            
            pred = self.predict_single_rating(user_id, item_id)
            predictions.append(pred)
        
        return np.array(predictions)
    
    def predict_single_rating(self, user_id, item_id):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞"""
        predictions = []
        
        # SVD –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.svd_model and user_id < self.user_item_matrix.shape[0]:
            user_factors = self.svd_model.transform(self.user_item_matrix[user_id:user_id+1])
            item_factors = self.svd_model.components_[:, item_id]
            svd_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
            predictions.append(('svd', svd_pred))
        
        # NMF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if self.nmf_model and user_id < self.user_item_matrix.shape[0]:
            user_factors = self.nmf_model.transform(self.user_item_matrix[user_id:user_id+1])
            item_factors = self.nmf_model.components_[:, item_id]
            nmf_pred = np.dot(user_factors, item_factors.reshape(-1, 1))[0, 0]
            predictions.append(('nmf', nmf_pred))
        
        # Item similarity –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if user_id < self.user_item_matrix.shape[0] and item_id < self.user_item_matrix.shape[1]:
            user_ratings = self.user_item_matrix[user_id]
            similar_items = self.item_similarity[item_id]
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–æ—Ö–æ–∂–∏–º —Ç–æ–≤–∞—Ä–∞–º
            numerator = np.sum(similar_items * user_ratings)
            denominator = np.sum(np.abs(similar_items))
            
            if denominator > 0:
                similarity_pred = numerator / denominator
                predictions.append(('similarity', similarity_pred))
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if predictions:
            weighted_sum = sum(pred * self.weights.get(method, 0.25) for method, pred in predictions)
            total_weight = sum(self.weights.get(method, 0.25) for method, _ in predictions)
            return weighted_sum / total_weight if total_weight > 0 else 2.5
        
        return 2.5  # –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def get_recommendations(self, magazin_name, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        if self.user_item_matrix is None:
            return None
        
        try:
            user_id = self.le_magazin.transform([magazin_name])[0]
        except:
            return None
        
        if user_id >= self.user_item_matrix.shape[0]:
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        n_items = self.user_item_matrix.shape[1]
        user_ratings = self.user_item_matrix[user_id]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        predictions = []
        for item_id in range(n_items):
            if user_ratings[item_id] == 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                pred_rating = self.predict_single_rating(user_id, item_id)
                predictions.append((item_id, pred_rating))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –≤—ã–±–æ—Ä —Ç–æ–ø-K
        predictions.sort(key=lambda x: x[1], reverse=True)
        top_items = predictions[:top_k]
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = []
        for rank, (item_id, score) in enumerate(top_items, 1):
            try:
                item_name = self.le_art.inverse_transform([item_id])[0]
                
                # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–µ
                item_info = self.processed_data[
                    self.processed_data['art_encoded'] == item_id
                ]
                
                if len(item_info) > 0:
                    info = item_info.iloc[0]
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': info['Segment'],
                        'model': info['Model'],
                        'avg_price': info['price_mean'],
                        'expected_qty': info['qty_mean']
                    }
                else:
                    rec = {
                        'rank': rank,
                        'item': item_name,
                        'score': score,
                        'segment': 'Unknown',
                        'model': 'Unknown',
                        'avg_price': 0,
                        'expected_qty': 0
                    }
                
                recommendations.append(rec)
            except:
                continue
        
        return recommendations
    
    def get_all_recommendations(self, top_k=10):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
        if self.user_item_matrix is None:
            return None
        
        all_recommendations = {}
        for magazin_name in self.le_magazin.classes_:
            recommendations = self.get_recommendations(magazin_name, top_k)
            if recommendations:
                all_recommendations[magazin_name] = recommendations
        
        return all_recommendations

def create_dashboard():
    st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", layout="wide")
    
    st.title("üõçÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–æ–≤")
    st.markdown("*–ê–Ω—Å–∞–º–±–ª—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤: SVD + NMF + –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + Content-based*")
    st.markdown("---")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
    if 'recommender' not in st.session_state:
        st.session_state.recommender = EnsembleRecommenderSystem()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.sidebar.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª", 
        type=['xlsx', 'xls'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: Magazin, Datasales, Art, Describe, Model, Segment, Price, Qty, Sum"
    )
    
    if uploaded_file is not None:
        try:
            # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            df = pd.read_excel(uploaded_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['Magazin', 'Datasales', 'Art', 'Describe', 'Model', 'Segment', 'Price', 'Qty']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
                return
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–ó–∞–ø–∏—Å–µ–π", len(df))
            with col2:
                st.metric("–ú–∞–≥–∞–∑–∏–Ω–æ–≤", df['Magazin'].nunique())
            with col3:
                st.metric("–¢–æ–≤–∞—Ä–æ–≤", df['Art'].nunique())
            with col4:
                st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", df['Segment'].nunique())
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if st.sidebar.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π..."):
                    metrics = st.session_state.recommender.build_ensemble_model(df)
                
                st.success("–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω!")
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("RMSE (train)", f"{metrics['train_rmse']:.3f}")
                with col2:
                    st.metric("RMSE (test)", f"{metrics['test_rmse']:.3f}")
                with col3:
                    st.metric("–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['sparsity']:.1%}")
                with col4:
                    overfitting = metrics['test_rmse'] - metrics['train_rmse']
                    st.metric("–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ", f"{overfitting:.3f}")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if st.session_state.recommender.user_item_matrix is not None:
                st.markdown("---")
                st.header("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                
                tab1, tab2, tab3 = st.tabs(["–î–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞", "–î–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"])
                
                with tab1:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        selected_shop = st.selectbox(
                            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∞–≥–∞–∑–∏–Ω:",
                            options=st.session_state.recommender.le_magazin.classes_
                        )
                    with col2:
                        top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 5, 20, 10)
                    
                    if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
                        recommendations = st.session_state.recommender.get_recommendations(selected_shop, top_k)
                        
                        if recommendations:
                            rec_df = pd.DataFrame(recommendations)
                            
                            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                            display_df = rec_df.copy()
                            display_df['score'] = display_df['score'].round(3)
                            display_df['avg_price'] = display_df['avg_price'].round(2)
                            display_df['expected_qty'] = display_df['expected_qty'].round(1)
                            
                            st.dataframe(display_df, use_container_width=True)
                            
                            # –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                            fig = px.bar(
                                rec_df.head(10), x='item', y='score',
                                title=f"–¢–æ–ø-10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {selected_shop}",
                                labels={'item': '–¢–æ–≤–∞—Ä', 'score': '–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥'},
                                color='score',
                                color_continuous_scale='viridis'
                            )
                            fig.update_xaxes(tickangle=45)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
                            segment_counts = rec_df['segment'].value_counts()
                            fig2 = px.pie(
                                values=segment_counts.values,
                                names=segment_counts.index,
                                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                            )
                            st.plotly_chart(fig2, use_container_width=True)
                
                with tab2:
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        batch_top_k = st.slider("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –º–∞–≥–∞–∑–∏–Ω:", 5, 15, 10)
                    with col2:
                        show_top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –¥–ª—è –æ—Ç—á–µ—Ç–∞:", 3, 10, 5)
                    
                    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"):
                        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π..."):
                            all_recs = st.session_state.recommender.get_all_recommendations(batch_top_k)
                        
                        if all_recs:
                            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                            summary_data = []
                            for shop, recs in all_recs.items():
                                for rec in recs[:show_top_n]:
                                    summary_data.append({
                                        '–ú–∞–≥–∞–∑–∏–Ω': shop,
                                        '–†–∞–Ω–≥': rec['rank'],
                                        '–¢–æ–≤–∞—Ä': rec['item'],
                                        '–ü—Ä–æ–≥–Ω–æ–∑': f"{rec['score']:.3f}",
                                        '–°–µ–≥–º–µ–Ω—Ç': rec['segment'],
                                        '–ú–æ–¥–µ–ª—å': rec['model'],
                                        '–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞': f"{rec['avg_price']:.2f}",
                                        '–û–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª-–≤–æ': f"{rec['expected_qty']:.1f}"
                                    })
                            
                            summary_df = pd.DataFrame(summary_data)
                            st.dataframe(summary_df, use_container_width=True)
                            
                            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("–í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π", len(summary_data))
                            with col2:
                                avg_score = np.mean([float(x) for x in summary_df['–ü—Ä–æ–≥–Ω–æ–∑']])
                                st.metric("–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ–≥–Ω–æ–∑", f"{avg_score:.3f}")
                            with col3:
                                unique_items = summary_df['–¢–æ–≤–∞—Ä'].nunique()
                                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤", unique_items)
                            
                            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            @st.cache_data
                            def convert_df(df):
                                return df.to_csv(index=False).encode('utf-8')
                            
                            csv = convert_df(summary_df)
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (CSV)",
                                data=csv,
                                file_name='ensemble_recommendations.csv',
                                mime='text/csv'
                            )
                
                with tab3:
                    if st.session_state.recommender.processed_data is not None:
                        data = st.session_state.recommender.processed_data
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
                            fig1 = px.histogram(
                                data, x='rating', bins=20,
                                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤"
                            )
                            st.plotly_chart(fig1, use_container_width=True)
                        
                        with col2:
                            # –°–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É
                            segment_rating = data.groupby('Segment')['rating'].mean().sort_values(ascending=False)
                            fig2 = px.bar(
                                x=segment_rating.index, y=segment_rating.values,
                                title="–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º"
                            )
                            st.plotly_chart(fig2, use_container_width=True)
                        
                        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                        numeric_cols = ['qty_sum', 'revenue_sum', 'price_mean', 'freq', 'rating']
                        corr_matrix = data[numeric_cols].corr()
                        
                        fig3 = px.imshow(
                            corr_matrix, 
                            title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏",
                            aspect="auto"
                        )
                        st.plotly_chart(fig3, use_container_width=True)
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            st.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        
        # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        st.markdown("### üìã –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        example_data = {
            'Magazin': ['Shop_A', 'Shop_B', 'Shop_A', 'Shop_C'],
            'Datasales': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18'],
            'Art': ['Item_001', 'Item_002', 'Item_003', 'Item_001'],
            'Describe': ['–û–ø–∏—Å–∞–Ω–∏–µ 1', '–û–ø–∏—Å–∞–Ω–∏–µ 2', '–û–ø–∏—Å–∞–Ω–∏–µ 3', '–û–ø–∏—Å–∞–Ω–∏–µ 1'],
            'Model': ['Model_X', 'Model_Y', 'Model_Z', 'Model_X'],
            'Segment': ['Electronics', 'Clothing', 'Electronics', 'Electronics'],
            'Price': [100, 50, 150, 105],
            'Qty': [2, 1, 3, 1],
            'Sum': [200, 50, 450, 105]
        }
        example_df = pd.DataFrame(example_data)
        st.dataframe(example_df, use_container_width=True)
        
        st.markdown("### üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:")
        st.markdown("""
        - **SVD**: –ú–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        - **NMF**: –ù–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏  
        - **Item-based CF**: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
        - **Content-based**: –£—á–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ Random Forest
        - **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
        """)

if __name__ == "__main__":
    create_dashboard()